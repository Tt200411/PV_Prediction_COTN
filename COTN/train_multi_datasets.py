#!/usr/bin/env python3
"""
COTNå¤šæ•°æ®é›†è®­ç»ƒè„šæœ¬
ä¿®å¤äº†train/vali/teståˆ†å‰²é€»è¾‘ï¼Œæ”¯æŒå‘½ä»¤è¡Œå‚æ•°å’Œæ‰¹é‡è®­ç»ƒ
"""

import argparse
import os
import sys
import traceback
from exp.exp_config import InformerConfig
from exp.exp_informer import Exp_Informer
import torch

def parse_args():
    parser = argparse.ArgumentParser(description='COTNå…‰ä¼å‘ç”µé¢„æµ‹è®­ç»ƒ')
    
    # åŸºæœ¬å‚æ•°
    parser.add_argument('--datasets', type=str, nargs='+', 
                       default=['Site_1_50MW'], 
                       help='è¦è®­ç»ƒçš„æ•°æ®é›†åˆ—è¡¨ (å¯å¤šä¸ª)')
    parser.add_argument('--activation', type=str, default='lee', 
                       choices=['lee', 'relu'], 
                       help='æ¿€æ´»å‡½æ•°ç±»å‹')
    parser.add_argument('--lee_type', type=int, default=3, 
                       help='LeeæŒ¯è¡å™¨ç±»å‹ (1-8)')
    parser.add_argument('--pred_len', type=int, default=100, 
                       help='é¢„æµ‹é•¿åº¦')
    
    # è®­ç»ƒå‚æ•°
    parser.add_argument('--epochs', type=int, default=6, 
                       help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--batch_size', type=int, default=32, 
                       help='æ‰¹å¤§å°')
    parser.add_argument('--learning_rate', type=float, default=1e-4, 
                       help='å­¦ä¹ ç‡')
    parser.add_argument('--patience', type=int, default=3, 
                       help='æ—©åœè€å¿ƒå€¼')
    
    # æ¨¡å¼é€‰æ‹©
    parser.add_argument('--train_only', action='store_true', 
                       help='ä»…è®­ç»ƒæ¨¡å¼')
    parser.add_argument('--test_only', action='store_true', 
                       help='ä»…æµ‹è¯•æ¨¡å¼')
    parser.add_argument('--skip_test', action='store_true', 
                       help='è·³è¿‡æµ‹è¯•é˜¶æ®µ')
    
    # GPUè®¾ç½®
    parser.add_argument('--use_gpu', type=bool, default=True, 
                       help='æ˜¯å¦ä½¿ç”¨GPU')
    parser.add_argument('--gpu', type=int, default=0, 
                       help='GPUè®¾å¤‡ID')
    
    # å…¶ä»–è®¾ç½®
    parser.add_argument('--save_results', action='store_true', 
                       help='ä¿å­˜è¯¦ç»†ç»“æœ')
    parser.add_argument('--verbose', action='store_true', 
                       help='è¯¦ç»†è¾“å‡º')
    
    return parser.parse_args()


def create_config(dataset_name, args):
    """ä¸ºæŒ‡å®šæ•°æ®é›†åˆ›å»ºé…ç½®"""
    config = InformerConfig()
    
    # æ•°æ®é›†é…ç½®
    config.data = dataset_name
    config.data_path = f'{dataset_name}.csv'
    
    # æ¨¡å‹é…ç½®
    config.pred_len = args.pred_len
    config.train_epochs = args.epochs
    config.batch_size = args.batch_size
    config.learning_rate = args.learning_rate
    config.patience = args.patience
    
    # æ¿€æ´»å‡½æ•°é…ç½®
    if args.activation == 'relu':
        config.activation = 'relu'
        config.lee_oscillator = False
        config.use_relu = True
    else:
        config.activation = 'Lee'
        config.lee_oscillator = True
        config.use_relu = False
        config.lee_type = args.lee_type
    
    # GPUé…ç½®
    config.use_gpu = torch.cuda.is_available() and args.use_gpu
    config.gpu = args.gpu
    config.device = f'cuda:{args.gpu}'
    
    # æ–‡ä»¶åé…ç½®
    config.include_pred_len_in_filename = True
    
    if args.verbose:
        print(f"é…ç½®è¯¦æƒ… - {dataset_name}:")
        print(f"  é¢„æµ‹é•¿åº¦: {config.pred_len}")
        print(f"  æ¿€æ´»å‡½æ•°: {config.activation}")
        print(f"  è®­ç»ƒè½®æ•°: {config.train_epochs}")
        print(f"  è®¾å¤‡: {'GPU' if config.use_gpu else 'CPU'}")
    
    return config


def train_single_dataset(dataset_name, args):
    """è®­ç»ƒå•ä¸ªæ•°æ®é›†"""
    print(f"\n{'='*80}")
    print(f"å¼€å§‹è®­ç»ƒæ•°æ®é›†: {dataset_name}")
    print(f"{'='*80}")
    
    try:
        # åˆ›å»ºé…ç½®
        config = create_config(dataset_name, args)
        
        # æ£€æŸ¥æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        data_file = os.path.join(config.root_path, config.data_path)
        if not os.path.exists(data_file):
            print(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_file}")
            return None
        
        # åˆ›å»ºå®éªŒå®ä¾‹
        exp = Exp_Informer(config)
        
        # ç”Ÿæˆè®¾ç½®æ ‡è¯†
        activation_suffix = 'relu' if getattr(config, 'use_relu', False) else f'lee{config.lee_type}'
        setting = f'informer_{dataset_name}_{activation_suffix}_pred{config.pred_len}'
        
        print(f"è®­ç»ƒè®¾ç½®: {setting}")
        
        result = {'dataset': dataset_name, 'setting': setting}
        
        # è®­ç»ƒé˜¶æ®µ
        if not args.test_only:
            print(f"ğŸš€ å¼€å§‹è®­ç»ƒ...")
            import time
            start_time = time.time()
            
            train_result = exp.train(setting)
            
            end_time = time.time()
            training_time = end_time - start_time
            print(f"âœ… è®­ç»ƒå®Œæˆï¼Œè€—æ—¶: {training_time:.2f}ç§’")
            
            result['train_result'] = train_result
        
        # æµ‹è¯•é˜¶æ®µ
        if not args.train_only and not args.skip_test:
            print(f"ğŸ§ª å¼€å§‹æµ‹è¯•...")
            test_result = exp.test(setting)
            print(f"âœ… æµ‹è¯•å®Œæˆ")
            result['test_result'] = test_result
            
            # é¢„æµ‹è¯„ä¼°
            print(f"ğŸ“Š ç”Ÿæˆé¢„æµ‹ç»“æœ...")
            pred_result = exp.predict(setting, load=True)
            result['pred_result'] = pred_result
        
        return result
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒå¤±è´¥: {e}")
        if args.verbose:
            traceback.print_exc()
        return None


def main():
    args = parse_args()
    
    print(f"COTNå¤šæ•°æ®é›†è®­ç»ƒå·¥å…·")
    print(f"{'='*80}")
    print(f"æ•°æ®é›†: {args.datasets}")
    print(f"æ¿€æ´»å‡½æ•°: {args.activation}")
    print(f"é¢„æµ‹é•¿åº¦: {args.pred_len}")
    print(f"è®­ç»ƒæ¨¡å¼: {'ä»…è®­ç»ƒ' if args.train_only else 'ä»…æµ‹è¯•' if args.test_only else 'è®­ç»ƒ+æµ‹è¯•'}")
    print(f"GPUåŠ é€Ÿ: {torch.cuda.is_available()}")
    print(f"{'='*80}")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„æ•°æ®é›†
    available_datasets = []
    data_dir = "ETT-small"
    
    for dataset in args.datasets:
        csv_file = os.path.join(data_dir, f"{dataset}.csv")
        if os.path.exists(csv_file):
            available_datasets.append(dataset)
        else:
            print(f"âš ï¸  æ•°æ®é›† {dataset} çš„CSVæ–‡ä»¶ä¸å­˜åœ¨: {csv_file}")
    
    if not available_datasets:
        print("âŒ æ²¡æœ‰å¯ç”¨çš„æ•°æ®é›†ï¼Œè¯·æ£€æŸ¥æ•°æ®æ–‡ä»¶")
        return
    
    print(f"âœ… æ‰¾åˆ° {len(available_datasets)} ä¸ªå¯ç”¨æ•°æ®é›†")
    
    # è®­ç»ƒç»“æœç»Ÿè®¡
    successful_trainings = 0
    failed_trainings = 0
    results = {}
    
    # å¼€å§‹æ‰¹é‡è®­ç»ƒ
    for i, dataset in enumerate(available_datasets, 1):
        print(f"\nè¿›åº¦: [{i}/{len(available_datasets)}]")
        
        result = train_single_dataset(dataset, args)
        
        if result:
            results[dataset] = result
            successful_trainings += 1
            print(f"âœ… {dataset} è®­ç»ƒæˆåŠŸ")
        else:
            failed_trainings += 1
            print(f"âŒ {dataset} è®­ç»ƒå¤±è´¥")
    
    # æ€»ç»“æŠ¥å‘Š
    print(f"\n{'='*80}")
    print(f"è®­ç»ƒå®Œæˆæ€»ç»“")
    print(f"{'='*80}")
    print(f"æ€»æ•°æ®é›†: {len(available_datasets)}")
    print(f"æˆåŠŸè®­ç»ƒ: {successful_trainings}")
    print(f"å¤±è´¥è®­ç»ƒ: {failed_trainings}")
    print(f"æˆåŠŸç‡: {successful_trainings/len(available_datasets)*100:.1f}%")
    
    if args.save_results and results:
        # ä¿å­˜è¯¦ç»†ç»“æœ
        import json
        result_file = f"training_results_{args.activation}_pred{args.pred_len}.json"
        with open(result_file, 'w', encoding='utf-8') as f:
            # ç®€åŒ–resultsä»¥ä¾¿JSONåºåˆ—åŒ–
            simple_results = {}
            for dataset, result in results.items():
                simple_results[dataset] = {
                    'dataset': result['dataset'],
                    'setting': result['setting'],
                    'success': True
                }
            json.dump(simple_results, f, indent=2, ensure_ascii=False)
        print(f"ğŸ“„ è¯¦ç»†ç»“æœå·²ä¿å­˜: {result_file}")
    
    print(f"{'='*80}")


if __name__ == "__main__":
    main()